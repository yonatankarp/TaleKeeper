services:
  talekeeper:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ./data/db:/app/data/db
      - ./data/audio:/app/data/audio
      - ./data/images:/app/data/images
    environment:
      - LLM_BASE_URL=http://ollama:11434/v1
      - IMAGE_API_KEY=${IMAGE_API_KEY:-}
      - IMAGE_MODEL=${IMAGE_MODEL:-}
      - TALEKEEPER_SECRET=${TALEKEEPER_SECRET:-}
    depends_on:
      - ollama

  ollama:
    image: ollama/ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    entrypoint: /bin/sh
    command:
      - -c
      - "ollama serve & sleep 10 && ollama pull llama3.1:8b && wait"

volumes:
  ollama_models:
